{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An Introduction to SageMaker LDA in R\n",
    "#### R implementation counterpart of \"An Introduction to SageMaker LDA\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Amazon SageMaker LDA** is an unsupervised learning algorithm that attempts to describe a set of observations as a mixture of distinct categories. **Latent Dirichlet Allocation (LDA)** is most commonly used to discover a user-specified number of topics shared by documents within a text corpus. \n",
    "\n",
    "In this notebook, we will demonstrate the `R` implementation counterpart of **An Introduction to SageMaker LDA** written in `Python`. Given that majority of the SageMaker sample notebooks are written in `Python`, data scientists already using the `R` language can use this notebook as a reference so that they are not forced to convert existing scripts and notebooks already written with the `R` language.\n",
    "\n",
    "Similar to the original notebook written in `Python`, the following are not the goals of this notebook:\n",
    "\n",
    "- discuss and interpret the generated synthetic document data\n",
    "- understand the LDA model\n",
    "- interpret the meaning of the inference output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I. Setting Up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `reticulate` package allows `Python` code to be executed in `R`. The `import` statement below is the `R` counterpart of the `Python import` statement. The `reticulate` package has allowed the `Python` code below to be written and executed in `R` seamlessly.\n",
    "\n",
    "```\n",
    "import sagemaker\n",
    "\n",
    "session = sagemaker.Session()\n",
    "\n",
    "...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(reticulate)\n",
    "sagemaker <- import('sagemaker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "session <- sagemaker$Session()\n",
    "\n",
    "bucket <- '581320662326-sagemaker-ap-southeast-2'\n",
    "prefix <- 'sagemaker/DEMO-lda-introduction'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `role_arn` is the IAM Role ARN used to give training and hosting access to your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "'arn:aws:iam::581320662326:role/SuperAdminRole'"
      ],
      "text/latex": [
       "'arn:aws:iam::581320662326:role/SuperAdminRole'"
      ],
      "text/markdown": [
       "'arn:aws:iam::581320662326:role/SuperAdminRole'"
      ],
      "text/plain": [
       "[1] \"arn:aws:iam::581320662326:role/SuperAdminRole\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "role_arn <- sagemaker$get_execution_role()\n",
    "role_arn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Python` code below translates to the next set of `R` statements to get the target `container` for the current `region`.\n",
    "\n",
    "```\n",
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "\n",
    "region_name = boto3.Session().region_name\n",
    "container = get_image_uri(region_name, 'lda')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "'297031611018.dkr.ecr.ap-southeast-2.amazonaws.com/lda:latest'"
      ],
      "text/latex": [
       "'297031611018.dkr.ecr.ap-southeast-2.amazonaws.com/lda:latest'"
      ],
      "text/markdown": [
       "'297031611018.dkr.ecr.ap-southeast-2.amazonaws.com/lda:latest'"
      ],
      "text/plain": [
       "[1] \"297031611018.dkr.ecr.ap-southeast-2.amazonaws.com/lda:latest\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "registry <- sagemaker$amazon$amazon_estimator$registry(session$boto_region_name, algorithm='lda')\n",
    "container <- paste(registry, '/lda:latest', sep='')\n",
    "\n",
    "container"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II. Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Python` code below translates to the next set of `R` statements. The set of statements below involve setting and specifying the general training job information along with the hyperparameters for LDA.\n",
    "\n",
    "```\n",
    "lda = sagemaker.estimator.Estimator(\n",
    "    container,\n",
    "    role,\n",
    "    output_path='s3://{}/{}/output'.format(bucket, prefix),\n",
    "    train_instance_count=1,\n",
    "    train_instance_type='ml.c4.2xlarge',\n",
    "    sagemaker_session=session,\n",
    ")\n",
    "\n",
    "lda.set_hyperparameters(\n",
    "    num_topics=num_topics,\n",
    "    feature_dim=vocabulary_size,\n",
    "    mini_batch_size=num_documents_training,\n",
    "    alpha0=1.0,\n",
    ")\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_output <- paste0('s3://', bucket, '/output')\n",
    "estimator <- sagemaker$estimator$Estimator(image_name = container,\n",
    "                                           role = role_arn,\n",
    "                                           train_instance_count = 1L,\n",
    "                                           train_instance_type = 'ml.c4.2xlarge',\n",
    "                                           output_path = s3_output,\n",
    "                                           output_kms_key = NULL,\n",
    "                                           base_job_name = NULL,\n",
    "                                           sagemaker_session = session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator$set_hyperparameters(num_topics = 5L, feature_dim=25L, mini_batch_size=45L)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we run the training job on the input data in S3. The training data (topic-mixture) used is generated using the `generate_griffiths_data` script provided in the original notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_name <- paste('sagemaker-train-lda-r', format(Sys.time(), '%H-%M-%S'), sep = '-')\n",
    "input_data <- list('train' = 's3://581320662326-sagemaker-ap-southeast-2/sagemaker/DEMO-lda-introduction/train/lda.data')\n",
    "\n",
    "estimator$fit(inputs = input_data,\n",
    "              job_name = job_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the training job has completed, the output model `model.tar.gz` is saved in `S3` as well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "'s3://581320662326-sagemaker-ap-southeast-2/output/sagemaker-train-lda-r-07-59-25/output/model.tar.gz'"
      ],
      "text/latex": [
       "'s3://581320662326-sagemaker-ap-southeast-2/output/sagemaker-train-lda-r-07-59-25/output/model.tar.gz'"
      ],
      "text/markdown": [
       "'s3://581320662326-sagemaker-ap-southeast-2/output/sagemaker-train-lda-r-07-59-25/output/model.tar.gz'"
      ],
      "text/plain": [
       "[1] \"s3://581320662326-sagemaker-ap-southeast-2/output/sagemaker-train-lda-r-07-59-25/output/model.tar.gz\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "estimator$model_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### III. Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once training is complete and we have the model, we generate an **endpoint** by using the **deploy** method with the *instance count* and *instance type* as the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_endpoint <- estimator$deploy(initial_instance_count = 1L,\n",
    "                                   instance_type = 'ml.t2.medium')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The deployed endpoint name can be accessed using `model_endpoint$endpoint`. The `Endpoints tab` in the Amazon SageMaker console should reflect the deployed endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "'sagemaker-train-lda-r-05-56-02'"
      ],
      "text/latex": [
       "'sagemaker-train-lda-r-05-56-02'"
      ],
      "text/markdown": [
       "'sagemaker-train-lda-r-05-56-02'"
      ],
      "text/plain": [
       "[1] \"sagemaker-train-lda-r-05-56-02\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_endpoint$endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Python` code below translates to the next set of `R` statements. The code below makes use of `csv_serializer` and `json_deserializer` to configure the inference endpoint.\n",
    "\n",
    "```\n",
    "from sagemaker.predictor import csv_serializer, json_deserializer\n",
    "\n",
    "lda_inference.content_type = 'text/csv'\n",
    "lda_inference.serializer = csv_serializer\n",
    "lda_inference.deserializer = json_deserializer\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_endpoint$content_type <- 'text/csv'\n",
    "model_endpoint$serializer <- sagemaker$predictor$csv_serializer\n",
    "model_endpoint$deserializer <- sagemaker$predictor$json_deserializer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the sample test data stored in `lda-test.csv`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>V1</th><th scope=col>V2</th><th scope=col>V3</th><th scope=col>V4</th><th scope=col>V5</th><th scope=col>V6</th><th scope=col>V7</th><th scope=col>V8</th><th scope=col>V9</th><th scope=col>V10</th><th scope=col>...</th><th scope=col>V16</th><th scope=col>V17</th><th scope=col>V18</th><th scope=col>V19</th><th scope=col>V20</th><th scope=col>V21</th><th scope=col>V22</th><th scope=col>V23</th><th scope=col>V24</th><th scope=col>V25</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>36 </td><td>1  </td><td> 0 </td><td>2  </td><td> 0 </td><td>24 </td><td>0  </td><td> 0 </td><td>3  </td><td> 0 </td><td>...</td><td>27 </td><td>2  </td><td> 0 </td><td>2  </td><td>0  </td><td>28 </td><td>1  </td><td> 0 </td><td>3  </td><td>0  </td></tr>\n",
       "\t<tr><td>32 </td><td>0  </td><td> 0 </td><td>0  </td><td> 1 </td><td>27 </td><td>0  </td><td> 0 </td><td>0  </td><td> 0 </td><td>...</td><td>32 </td><td>0  </td><td> 0 </td><td>0  </td><td>2  </td><td>23 </td><td>0  </td><td> 0 </td><td>0  </td><td>0  </td></tr>\n",
       "\t<tr><td> 3 </td><td>0  </td><td>23 </td><td>1  </td><td> 0 </td><td> 1 </td><td>0  </td><td>15 </td><td>5  </td><td> 0 </td><td>...</td><td> 2 </td><td>1  </td><td>30 </td><td>1  </td><td>0  </td><td> 1 </td><td>0  </td><td>14 </td><td>3  </td><td>0  </td></tr>\n",
       "\t<tr><td>18 </td><td>8  </td><td> 1 </td><td>0  </td><td>11 </td><td>10 </td><td>9  </td><td> 1 </td><td>0  </td><td>11 </td><td>...</td><td>12 </td><td>9  </td><td> 2 </td><td>0  </td><td>7  </td><td>16 </td><td>4  </td><td> 2 </td><td>0  </td><td>7  </td></tr>\n",
       "\t<tr><td>25 </td><td>0  </td><td> 0 </td><td>2  </td><td> 0 </td><td>30 </td><td>0  </td><td> 0 </td><td>0  </td><td> 4 </td><td>...</td><td>26 </td><td>0  </td><td> 0 </td><td>4  </td><td>0  </td><td>33 </td><td>0  </td><td> 0 </td><td>3  </td><td>2  </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllllllllllllllllllllllll}\n",
       " V1 & V2 & V3 & V4 & V5 & V6 & V7 & V8 & V9 & V10 & ... & V16 & V17 & V18 & V19 & V20 & V21 & V22 & V23 & V24 & V25\\\\\n",
       "\\hline\n",
       "\t 36  & 1   &  0  & 2   &  0  & 24  & 0   &  0  & 3   &  0  & ... & 27  & 2   &  0  & 2   & 0   & 28  & 1   &  0  & 3   & 0  \\\\\n",
       "\t 32  & 0   &  0  & 0   &  1  & 27  & 0   &  0  & 0   &  0  & ... & 32  & 0   &  0  & 0   & 2   & 23  & 0   &  0  & 0   & 0  \\\\\n",
       "\t  3  & 0   & 23  & 1   &  0  &  1  & 0   & 15  & 5   &  0  & ... &  2  & 1   & 30  & 1   & 0   &  1  & 0   & 14  & 3   & 0  \\\\\n",
       "\t 18  & 8   &  1  & 0   & 11  & 10  & 9   &  1  & 0   & 11  & ... & 12  & 9   &  2  & 0   & 7   & 16  & 4   &  2  & 0   & 7  \\\\\n",
       "\t 25  & 0   &  0  & 2   &  0  & 30  & 0   &  0  & 0   &  4  & ... & 26  & 0   &  0  & 4   & 0   & 33  & 0   &  0  & 3   & 2  \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| V1 | V2 | V3 | V4 | V5 | V6 | V7 | V8 | V9 | V10 | ... | V16 | V17 | V18 | V19 | V20 | V21 | V22 | V23 | V24 | V25 |\n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| 36  | 1   |  0  | 2   |  0  | 24  | 0   |  0  | 3   |  0  | ... | 27  | 2   |  0  | 2   | 0   | 28  | 1   |  0  | 3   | 0   |\n",
       "| 32  | 0   |  0  | 0   |  1  | 27  | 0   |  0  | 0   |  0  | ... | 32  | 0   |  0  | 0   | 2   | 23  | 0   |  0  | 0   | 0   |\n",
       "|  3  | 0   | 23  | 1   |  0  |  1  | 0   | 15  | 5   |  0  | ... |  2  | 1   | 30  | 1   | 0   |  1  | 0   | 14  | 3   | 0   |\n",
       "| 18  | 8   |  1  | 0   | 11  | 10  | 9   |  1  | 0   | 11  | ... | 12  | 9   |  2  | 0   | 7   | 16  | 4   |  2  | 0   | 7   |\n",
       "| 25  | 0   |  0  | 2   |  0  | 30  | 0   |  0  | 0   |  4  | ... | 26  | 0   |  0  | 4   | 0   | 33  | 0   |  0  | 3   | 2   |\n",
       "\n"
      ],
      "text/plain": [
       "  V1 V2 V3 V4 V5 V6 V7 V8 V9 V10 ... V16 V17 V18 V19 V20 V21 V22 V23 V24 V25\n",
       "1 36 1   0 2   0 24 0   0 3   0  ... 27  2    0  2   0   28  1    0  3   0  \n",
       "2 32 0   0 0   1 27 0   0 0   0  ... 32  0    0  0   2   23  0    0  0   0  \n",
       "3  3 0  23 1   0  1 0  15 5   0  ...  2  1   30  1   0    1  0   14  3   0  \n",
       "4 18 8   1 0  11 10 9   1 0  11  ... 12  9    2  0   7   16  4    2  0   7  \n",
       "5 25 0   0 2   0 30 0   0 0   4  ... 26  0    0  4   0   33  0    0  3   2  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_data <- read.csv(file = 'lda-test.csv', header=FALSE)\n",
    "head(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data <- as.matrix(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we use the inference endpoint to perform predictions using the test data provided. The `serializer` and `deserializer` used to configure the endpoint will automatically perform the datatype conversions required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions <- model_endpoint$predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<strong>$predictions</strong> = <ol>\n",
       "\t<li><strong>$topic_mixture</strong> = <ol class=list-inline>\n",
       "\t<li>0.083623006939888</li>\n",
       "\t<li>0.782742857933044</li>\n",
       "\t<li>0</li>\n",
       "\t<li>0.133634150028229</li>\n",
       "\t<li>0</li>\n",
       "</ol>\n",
       "</li>\n",
       "\t<li><strong>$topic_mixture</strong> = <ol class=list-inline>\n",
       "\t<li>0</li>\n",
       "\t<li>0.975672900676727</li>\n",
       "\t<li>0.0243270732462406</li>\n",
       "\t<li>0</li>\n",
       "\t<li>0</li>\n",
       "</ol>\n",
       "</li>\n",
       "\t<li><strong>$topic_mixture</strong> = <ol class=list-inline>\n",
       "\t<li>0.117042914032936</li>\n",
       "\t<li>0</li>\n",
       "\t<li>0</li>\n",
       "\t<li>0.0644981786608696</li>\n",
       "\t<li>0.81845897436142</li>\n",
       "</ol>\n",
       "</li>\n",
       "\t<li><strong>$topic_mixture</strong> = <ol class=list-inline>\n",
       "\t<li>0</li>\n",
       "\t<li>0</li>\n",
       "\t<li>0.262249231338501</li>\n",
       "\t<li>0.69550895690918</li>\n",
       "\t<li>0.0422417595982552</li>\n",
       "</ol>\n",
       "</li>\n",
       "\t<li><strong>$topic_mixture</strong> = <ol class=list-inline>\n",
       "\t<li>0.0760784968733788</li>\n",
       "\t<li>0.879879891872406</li>\n",
       "\t<li>0.0440415665507317</li>\n",
       "\t<li>0</li>\n",
       "\t<li>0</li>\n",
       "</ol>\n",
       "</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\textbf{\\$predictions} = \\begin{enumerate}\n",
       "\\item \\textbf{\\$topic\\_mixture} = \\begin{enumerate*}\n",
       "\\item 0.083623006939888\n",
       "\\item 0.782742857933044\n",
       "\\item 0\n",
       "\\item 0.133634150028229\n",
       "\\item 0\n",
       "\\end{enumerate*}\n",
       "\n",
       "\\item \\textbf{\\$topic\\_mixture} = \\begin{enumerate*}\n",
       "\\item 0\n",
       "\\item 0.975672900676727\n",
       "\\item 0.0243270732462406\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\end{enumerate*}\n",
       "\n",
       "\\item \\textbf{\\$topic\\_mixture} = \\begin{enumerate*}\n",
       "\\item 0.117042914032936\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0.0644981786608696\n",
       "\\item 0.81845897436142\n",
       "\\end{enumerate*}\n",
       "\n",
       "\\item \\textbf{\\$topic\\_mixture} = \\begin{enumerate*}\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0.262249231338501\n",
       "\\item 0.69550895690918\n",
       "\\item 0.0422417595982552\n",
       "\\end{enumerate*}\n",
       "\n",
       "\\item \\textbf{\\$topic\\_mixture} = \\begin{enumerate*}\n",
       "\\item 0.0760784968733788\n",
       "\\item 0.879879891872406\n",
       "\\item 0.0440415665507317\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\end{enumerate*}\n",
       "\n",
       "\\end{enumerate}\n"
      ],
      "text/markdown": [
       "**$predictions** = 1. **$topic_mixture** = 1. 0.083623006939888\n",
       "2. 0.782742857933044\n",
       "3. 0\n",
       "4. 0.133634150028229\n",
       "5. 0\n",
       "\n",
       "\n",
       "\n",
       "2. **$topic_mixture** = 1. 0\n",
       "2. 0.975672900676727\n",
       "3. 0.0243270732462406\n",
       "4. 0\n",
       "5. 0\n",
       "\n",
       "\n",
       "\n",
       "3. **$topic_mixture** = 1. 0.117042914032936\n",
       "2. 0\n",
       "3. 0\n",
       "4. 0.0644981786608696\n",
       "5. 0.81845897436142\n",
       "\n",
       "\n",
       "\n",
       "4. **$topic_mixture** = 1. 0\n",
       "2. 0\n",
       "3. 0.262249231338501\n",
       "4. 0.69550895690918\n",
       "5. 0.0422417595982552\n",
       "\n",
       "\n",
       "\n",
       "5. **$topic_mixture** = 1. 0.0760784968733788\n",
       "2. 0.879879891872406\n",
       "3. 0.0440415665507317\n",
       "4. 0\n",
       "5. 0\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "$predictions\n",
       "$predictions[[1]]\n",
       "$predictions[[1]]$topic_mixture\n",
       "[1] 0.08362301 0.78274286 0.00000000 0.13363415 0.00000000\n",
       "\n",
       "\n",
       "$predictions[[2]]\n",
       "$predictions[[2]]$topic_mixture\n",
       "[1] 0.00000000 0.97567290 0.02432707 0.00000000 0.00000000\n",
       "\n",
       "\n",
       "$predictions[[3]]\n",
       "$predictions[[3]]$topic_mixture\n",
       "[1] 0.11704291 0.00000000 0.00000000 0.06449818 0.81845897\n",
       "\n",
       "\n",
       "$predictions[[4]]\n",
       "$predictions[[4]]$topic_mixture\n",
       "[1] 0.00000000 0.00000000 0.26224923 0.69550896 0.04224176\n",
       "\n",
       "\n",
       "$predictions[[5]]\n",
       "$predictions[[5]]$topic_mixture\n",
       "[1] 0.07607850 0.87987989 0.04404157 0.00000000 0.00000000\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IV. Stop / Close the Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "session$delete_endpoint(model_endpoint$endpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### V. Epilogue\n",
    "\n",
    "In this notebook, we've used `reticulate` to convert an existing `SageMaker example notebook` written in `Python` to `R`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
